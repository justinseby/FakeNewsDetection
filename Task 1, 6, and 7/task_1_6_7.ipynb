{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing dependencies\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "# from sklearn import model_selection, preprocessing, linear_model, naive_bayes, metrics, svm\n",
    "# from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "# # from keras.preprocessing import text, sequence\n",
    "# # from keras import layers, models, optimizers\n",
    "# # import keras\n",
    "# import re\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# from sklearn.pipeline import Pipeline\n",
    "# from sklearn.metrics import roc_auc_score\n",
    "# from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "# from sklearn import decomposition, ensemble\n",
    "# import pandas as pd\n",
    "# import matplotlib.pyplot as plt\n",
    "# # import nltk\n",
    "# # from nltk.stem import PorterStemmer\n",
    "# # from nltk.wsd import lesk\n",
    "# import string\n",
    "\n",
    "#Util.py imports from the fakenewschallenge\n",
    "from csv import DictReader\n",
    "from csv import DictWriter\n",
    "import random\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics import accuracy_score,classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global Variables\n",
    "label_ref = {'agree': 0, 'disagree': 1, 'discuss': 2, 'unrelated': 3}\n",
    "label_ref_rev = {0: 'agree', 1: 'disagree', 2: 'discuss', 3: 'unrelated'}\n",
    "stop_words = [\n",
    "        \"a\", \"about\", \"above\", \"across\", \"after\", \"afterwards\", \"again\", \"against\", \"all\", \"almost\", \"alone\", \"along\",\n",
    "        \"already\", \"also\", \"although\", \"always\", \"am\", \"among\", \"amongst\", \"amoungst\", \"amount\", \"an\", \"and\", \"another\",\n",
    "        \"any\", \"anyhow\", \"anyone\", \"anything\", \"anyway\", \"anywhere\", \"are\", \"around\", \"as\", \"at\", \"back\", \"be\",\n",
    "        \"became\", \"because\", \"become\", \"becomes\", \"becoming\", \"been\", \"before\", \"beforehand\", \"behind\", \"being\",\n",
    "        \"below\", \"beside\", \"besides\", \"between\", \"beyond\", \"bill\", \"both\", \"bottom\", \"but\", \"by\", \"call\", \"can\", \"co\",\n",
    "        \"con\", \"could\", \"cry\", \"de\", \"describe\", \"detail\", \"do\", \"done\", \"down\", \"due\", \"during\", \"each\", \"eg\", \"eight\",\n",
    "        \"either\", \"eleven\", \"else\", \"elsewhere\", \"empty\", \"enough\", \"etc\", \"even\", \"ever\", \"every\", \"everyone\",\n",
    "        \"everything\", \"everywhere\", \"except\", \"few\", \"fifteen\", \"fifty\", \"fill\", \"find\", \"fire\", \"first\", \"five\", \"for\",\n",
    "        \"former\", \"formerly\", \"forty\", \"found\", \"four\", \"from\", \"front\", \"full\", \"further\", \"get\", \"give\", \"go\", \"had\",\n",
    "        \"has\", \"have\", \"he\", \"hence\", \"her\", \"here\", \"hereafter\", \"hereby\", \"herein\", \"hereupon\", \"hers\", \"herself\",\n",
    "        \"him\", \"himself\", \"his\", \"how\", \"however\", \"hundred\", \"i\", \"ie\", \"if\", \"in\", \"inc\", \"indeed\", \"interest\",\n",
    "        \"into\", \"is\", \"it\", \"its\", \"itself\", \"keep\", \"last\", \"latter\", \"latterly\", \"least\", \"less\", \"ltd\", \"made\",\n",
    "        \"many\", \"may\", \"me\", \"meanwhile\", \"might\", \"mill\", \"mine\", \"more\", \"moreover\", \"most\", \"mostly\", \"move\", \"much\",\n",
    "        \"must\", \"my\", \"myself\", \"name\", \"namely\", \"neither\", \"nevertheless\", \"next\", \"nine\", \"nobody\", \"now\", \"nowhere\",\n",
    "        \"of\", \"off\", \"often\", \"on\", \"once\", \"one\", \"only\", \"onto\", \"or\", \"other\", \"others\", \"otherwise\", \"our\", \"ours\",\n",
    "        \"ourselves\", \"out\", \"over\", \"own\", \"part\", \"per\", \"perhaps\", \"please\", \"put\", \"rather\", \"re\", \"same\", \"see\",\n",
    "        \"serious\", \"several\", \"she\", \"should\", \"show\", \"side\", \"since\", \"sincere\", \"six\", \"sixty\", \"so\", \"some\",\n",
    "        \"somehow\", \"someone\", \"something\", \"sometime\", \"sometimes\", \"somewhere\", \"still\", \"such\", \"system\", \"take\",\n",
    "        \"ten\", \"than\", \"that\", \"the\", \"their\", \"them\", \"themselves\", \"then\", \"thence\", \"there\", \"thereafter\", \"thereby\",\n",
    "        \"therefore\", \"therein\", \"thereupon\", \"these\", \"they\", \"thick\", \"thin\", \"third\", \"this\", \"those\", \"though\",\n",
    "        \"three\", \"through\", \"throughout\", \"thru\", \"thus\", \"to\", \"together\", \"too\", \"top\", \"toward\", \"towards\", \"twelve\",\n",
    "        \"twenty\", \"two\", \"un\", \"under\", \"until\", \"up\", \"upon\", \"us\", \"very\", \"via\", \"was\", \"we\", \"well\", \"were\", \"what\",\n",
    "        \"whatever\", \"when\", \"whence\", \"whenever\", \"where\", \"whereafter\", \"whereas\", \"whereby\", \"wherein\", \"whereupon\",\n",
    "        \"wherever\", \"whether\", \"which\", \"while\", \"whither\", \"who\", \"whoever\", \"whole\", \"whom\", \"whose\", \"why\", \"will\",\n",
    "        \"with\", \"within\", \"without\", \"would\", \"yet\", \"you\", \"your\", \"yours\", \"yourself\", \"yourselves\"\n",
    "        ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FNCData:\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    Define class for Fake News Challenge data\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, file_instances, file_bodies):\n",
    "\n",
    "        # Load data\n",
    "        self.instances = self.read(file_instances)\n",
    "        bodies = self.read(file_bodies)\n",
    "        self.heads = {}\n",
    "        self.bodies = {}\n",
    "\n",
    "        # Process instances\n",
    "        for instance in self.instances:\n",
    "            if instance['Headline'] not in self.heads:\n",
    "                head_id = len(self.heads)\n",
    "                self.heads[instance['Headline']] = head_id\n",
    "            instance['Body ID'] = int(instance['Body ID'])\n",
    "\n",
    "        # Process bodies\n",
    "        for body in bodies:\n",
    "            self.bodies[int(body['Body ID'])] = body['articleBody']\n",
    "\n",
    "    def read(self, filename):\n",
    "\n",
    "        \"\"\"\n",
    "        Read Fake News Challenge data from CSV file\n",
    "\n",
    "        Args:\n",
    "            filename: str, filename + extension\n",
    "\n",
    "        Returns:\n",
    "            rows: list, of dict per instance\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        # Initialise\n",
    "        rows = []\n",
    "\n",
    "        # Process file\n",
    "        with open(filename, \"r\", encoding='utf-8') as table:\n",
    "            r = DictReader(table)\n",
    "            for line in r:\n",
    "                rows.append(line)\n",
    "\n",
    "        return rows\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pipeline_train(train, test, lim_unigram):\n",
    "    \"\"\"\n",
    "\n",
    "    Process train set, create relevant vectorizers\n",
    "\n",
    "    Args:\n",
    "        train: FNCData object, train set\n",
    "        test: FNCData object, test set\n",
    "        lim_unigram: int, number of most frequent words to consider\n",
    "\n",
    "    Returns:\n",
    "        train_set: list, of numpy arrays\n",
    "        train_stances: list, of ints\n",
    "        bow_vectorizer: sklearn CountVectorizer\n",
    "        tfreq_vectorizer: sklearn TfidfTransformer(use_idf=False)\n",
    "        tfidf_vectorizer: sklearn TfidfVectorizer()\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    # Initialise\n",
    "    heads = []\n",
    "    heads_track = {}\n",
    "    bodies = []\n",
    "    bodies_track = {}\n",
    "    body_ids = []\n",
    "    id_ref = {}\n",
    "    train_set = []\n",
    "    train_stances = []\n",
    "    cos_track = {}\n",
    "    test_heads = []\n",
    "    test_heads_track = {}\n",
    "    test_bodies = []\n",
    "    test_bodies_track = {}\n",
    "    test_body_ids = []\n",
    "    head_tfidf_track = {}\n",
    "    body_tfidf_track = {}\n",
    "\n",
    "    # Identify unique heads and bodies\n",
    "    for instance in train.instances:\n",
    "        head = instance['Headline']\n",
    "        #print(head)\n",
    "        body_id = instance['Body ID']\n",
    "        #print(body_id)\n",
    "        if head not in heads_track:\n",
    "            heads.append(head)\n",
    "            heads_track[head] = 1\n",
    "        if body_id not in bodies_track:\n",
    "            #print(train.bodies[body_id])\n",
    "            bodies.append(train.bodies[body_id])\n",
    "            bodies_track[body_id] = 1\n",
    "            body_ids.append(body_id)\n",
    "\n",
    "    for instance in test.instances:\n",
    "        head = instance['Headline']\n",
    "        body_id = instance['Body ID']\n",
    "        if head not in test_heads_track:\n",
    "            test_heads.append(head)\n",
    "            test_heads_track[head] = 1\n",
    "        if body_id not in test_bodies_track:\n",
    "            test_bodies.append(test.bodies[body_id])\n",
    "            test_bodies_track[body_id] = 1\n",
    "            test_body_ids.append(body_id)\n",
    "\n",
    "    # Create reference dictionary\n",
    "    for i, elem in enumerate(heads + body_ids):\n",
    "        id_ref[elem] = i\n",
    "\n",
    "    # Create vectorizers and BOW and TF arrays for train set\n",
    "    bow_vectorizer = CountVectorizer(max_features=lim_unigram, stop_words=stop_words)\n",
    "    bow = bow_vectorizer.fit_transform(heads + bodies)  # Train set only\n",
    "\n",
    "    tfreq_vectorizer = TfidfTransformer(use_idf=False).fit(bow)\n",
    "    tfreq = tfreq_vectorizer.transform(bow).toarray()  # Train set only\n",
    "\n",
    "    tfidf_vectorizer = TfidfVectorizer(max_features=lim_unigram, stop_words=stop_words).\\\n",
    "        fit(heads + bodies + test_heads + test_bodies)  # Train and test sets\n",
    "\n",
    "    # Process train set\n",
    "    for instance in train.instances:\n",
    "        head = instance['Headline']\n",
    "        body_id = instance['Body ID']\n",
    "        head_tf = tfreq[id_ref[head]].reshape(1, -1)\n",
    "        body_tf = tfreq[id_ref[body_id]].reshape(1, -1)\n",
    "        if head not in head_tfidf_track:\n",
    "            head_tfidf = tfidf_vectorizer.transform([head]).toarray()\n",
    "            head_tfidf_track[head] = head_tfidf\n",
    "        else:\n",
    "            head_tfidf = head_tfidf_track[head]\n",
    "        if body_id not in body_tfidf_track:\n",
    "            body_tfidf = tfidf_vectorizer.transform([train.bodies[body_id]]).toarray()\n",
    "            body_tfidf_track[body_id] = body_tfidf\n",
    "        else:\n",
    "            body_tfidf = body_tfidf_track[body_id]\n",
    "        if (head, body_id) not in cos_track:\n",
    "            tfidf_cos = cosine_similarity(head_tfidf, body_tfidf)[0].reshape(1, 1)\n",
    "            cos_track[(head, body_id)] = tfidf_cos\n",
    "        else:\n",
    "            tfidf_cos = cos_track[(head, body_id)]\n",
    "        feat_vec = np.squeeze(np.c_[head_tf, body_tf, tfidf_cos])\n",
    "        train_set.append(feat_vec)\n",
    "        train_stances.append(label_ref[instance['Stance']])\n",
    "\n",
    "    return train_set, train_stances, bow_vectorizer, tfreq_vectorizer, tfidf_vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pipeline_test(test, bow_vectorizer, tfreq_vectorizer, tfidf_vectorizer):\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    Process test set\n",
    "\n",
    "    Args:\n",
    "        test: FNCData object, test set\n",
    "        bow_vectorizer: sklearn CountVectorizer\n",
    "        tfreq_vectorizer: sklearn TfidfTransformer(use_idf=False)\n",
    "        tfidf_vectorizer: sklearn TfidfVectorizer()\n",
    "\n",
    "    Returns:\n",
    "        test_set: list, of numpy arrays\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    # Initialise\n",
    "    test_set = []\n",
    "    heads_track = {}\n",
    "    bodies_track = {}\n",
    "    cos_track = {}\n",
    "\n",
    "    # Process test set\n",
    "    for instance in test.instances:\n",
    "        head = instance['Headline']\n",
    "        body_id = instance['Body ID']\n",
    "        if head not in heads_track:\n",
    "            head_bow = bow_vectorizer.transform([head]).toarray()\n",
    "            head_tf = tfreq_vectorizer.transform(head_bow).toarray()[0].reshape(1, -1)\n",
    "            head_tfidf = tfidf_vectorizer.transform([head]).toarray().reshape(1, -1)\n",
    "            heads_track[head] = (head_tf, head_tfidf)\n",
    "        else:\n",
    "            head_tf = heads_track[head][0]\n",
    "            head_tfidf = heads_track[head][1]\n",
    "        if body_id not in bodies_track:\n",
    "            body_bow = bow_vectorizer.transform([test.bodies[body_id]]).toarray()\n",
    "            body_tf = tfreq_vectorizer.transform(body_bow).toarray()[0].reshape(1, -1)\n",
    "            body_tfidf = tfidf_vectorizer.transform([test.bodies[body_id]]).toarray().reshape(1, -1)\n",
    "            bodies_track[body_id] = (body_tf, body_tfidf)\n",
    "        else:\n",
    "            body_tf = bodies_track[body_id][0]\n",
    "            body_tfidf = bodies_track[body_id][1]\n",
    "        if (head, body_id) not in cos_track:\n",
    "            tfidf_cos = cosine_similarity(head_tfidf, body_tfidf)[0].reshape(1, 1)\n",
    "            cos_track[(head, body_id)] = tfidf_cos\n",
    "        else:\n",
    "            tfidf_cos = cos_track[(head, body_id)]\n",
    "        feat_vec = np.squeeze(np.c_[head_tf, body_tf, tfidf_cos])\n",
    "        test_set.append(feat_vec)\n",
    "\n",
    "    return test_set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_predictions(pred, file):\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    Save predictions to CSV file\n",
    "\n",
    "    Args:\n",
    "        pred: numpy array, of numeric predictions\n",
    "        file: str, filename + extension\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    with open(file, 'w') as csvfile:\n",
    "        fieldnames = ['Stance']\n",
    "        writer = DictWriter(csvfile, fieldnames=fieldnames)\n",
    "\n",
    "        writer.writeheader()\n",
    "        for instance in pred:\n",
    "            writer.writerow({'Stance': label_ref_rev[instance]})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fixed Variables for the code\n",
    "\n",
    "# file names pointing to covid dataset\n",
    "file_train_instances = \"corona_train_stances.csv\"\n",
    "file_train_bodies = \"corona_train_bodies.csv\"\n",
    "file_test_instances = \"corona_test_stances_unlabeled.csv\"\n",
    "file_test_bodies = \"corona_test_bodies.csv\"\n",
    "file_test_instances_labeled = \"corona_test_stances_labeled.csv\"\n",
    "\n",
    "# file names pointing to economic dataset\n",
    "#file_train_instances = \"economic_train_stances.csv\"\n",
    "#file_train_bodies = \"economic_train_bodies.csv\"\n",
    "#file_test_instances = \"economic_test_stances_unlabeled.csv\"\n",
    "#file_test_bodies = \"economic_test_bodies.csv\"\n",
    "#file_test_instances_labeled = \"economic_test_stances_labeled.csv\"\n",
    "\n",
    "# file names pointing to fake news competition dataset\n",
    "#file_train_instances = \"train_stances.csv\"\n",
    "#file_train_bodies = \"train_bodies.csv\"\n",
    "#file_test_instances = \"test_stances_unlabeled.csv\"\n",
    "#file_test_bodies = \"test_bodies.csv\"\n",
    "#file_test_instances_labeled = 'predictions_test.csv'\n",
    "\n",
    "\n",
    "# Initialise hyperparameters\n",
    "r = random.Random()\n",
    "lim_unigram = 5000\n",
    "target_size = 4\n",
    "hidden_size = 100\n",
    "train_keep_prob = 0.6\n",
    "l2_alpha = 0.00001\n",
    "learn_rate = 0.01\n",
    "clip_ratio = 5\n",
    "batch_size_train = 500\n",
    "epochs = 90"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<__main__.FNCData object at 0x000001E480165D48>\n",
      "\n",
      "<__main__.FNCData object at 0x000001E480165E88>\n",
      "\n",
      "157\n"
     ]
    }
   ],
   "source": [
    "# Load data sets\n",
    "raw_train = FNCData(file_train_instances, file_train_bodies)\n",
    "raw_test = FNCData(file_test_instances, file_test_bodies)\n",
    "n_train = len(raw_train.instances)\n",
    "\n",
    "print(raw_train)\n",
    "print()\n",
    "print(raw_test)\n",
    "print()\n",
    "print(n_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Process Data Sets\n",
    "train_set, train_stances, bow_vectorizer, tfreq_vectorizer, tfidf_vectorizer = pipeline_train(raw_train, raw_test, lim_unigram=lim_unigram)\n",
    "feature_size = len(train_set[0])\n",
    "test_set = pipeline_test(raw_test, bow_vectorizer, tfreq_vectorizer, tfidf_vectorizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = np.array(test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_set = np.array(train_set)\n",
    "train_stances = np.array(train_stances)\n",
    "X_train,X_valid,y_train,y_valid = train_test_split(train_set,train_stances,test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\fuzel\\AppData\\Local\\Temp\\ipykernel_18776\\3465152102.py:3: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:\n",
      "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "  * https://github.com/tensorflow/io (for I/O related ops)\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\fuzel\\anaconda3\\envs\\tf1\\lib\\site-packages\\tensorflow_core\\contrib\\layers\\python\\layers\\layers.py:1866: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `layer.__call__` method instead.\n",
      "WARNING:tensorflow:From C:\\Users\\fuzel\\AppData\\Local\\Temp\\ipykernel_18776\\3465152102.py:11: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From C:\\Users\\fuzel\\AppData\\Local\\Temp\\ipykernel_18776\\3465152102.py:16: The name tf.trainable_variables is deprecated. Please use tf.compat.v1.trainable_variables instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Define model\n",
    "# Create placeholders\n",
    "features_pl = tf.placeholder(tf.float32, [None, feature_size], 'features')\n",
    "stances_pl = tf.placeholder(tf.int64, [None], 'stances')\n",
    "keep_prob_pl = tf.placeholder(tf.float32)\n",
    "\n",
    "# Infer batch size\n",
    "batch_size = tf.shape(features_pl)[0]\n",
    "\n",
    "# Define multi-layer perceptron\n",
    "hidden_layer = tf.nn.dropout(tf.nn.relu(tf.contrib.layers.linear(features_pl, hidden_size)), keep_prob=keep_prob_pl)\n",
    "logits_flat = tf.nn.dropout(tf.contrib.layers.linear(hidden_layer, target_size), keep_prob=keep_prob_pl)\n",
    "logits = tf.reshape(logits_flat, [batch_size, target_size])\n",
    "\n",
    "# Define L2 loss\n",
    "tf_vars = tf.trainable_variables()\n",
    "l2_loss = tf.add_n([tf.nn.l2_loss(v) for v in tf_vars if 'bias' not in v.name]) * l2_alpha\n",
    "\n",
    "# Define overall loss\n",
    "loss = tf.reduce_sum(tf.nn.sparse_softmax_cross_entropy_with_logits(labels=stances_pl, logits=logits) + l2_loss)\n",
    "\n",
    "# Define prediction\n",
    "softmaxed_logits = tf.nn.softmax(logits)\n",
    "predict = tf.argmax(softmaxed_logits, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\fuzel\\AppData\\Local\\Temp\\ipykernel_18776\\1229101498.py:2: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\fuzel\\anaconda3\\envs\\tf1\\lib\\site-packages\\tensorflow_core\\python\\ops\\clip_ops.py:301: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From C:\\Users\\fuzel\\AppData\\Local\\Temp\\ipykernel_18776\\1229101498.py:7: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\fuzel\\AppData\\Local\\Temp\\ipykernel_18776\\1229101498.py:8: The name tf.global_variables_initializer is deprecated. Please use tf.compat.v1.global_variables_initializer instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Define optimiser\n",
    "opt_func = tf.train.AdamOptimizer(learn_rate)\n",
    "grads, _ = tf.clip_by_global_norm(tf.gradients(loss, tf_vars), clip_ratio)\n",
    "opt_op = opt_func.apply_gradients(zip(grads, tf_vars))\n",
    "\n",
    "# Perform training\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        total_loss = 0\n",
    "        indices = list(range(n_train))\n",
    "        r.shuffle(indices)\n",
    "\n",
    "        for i in range(n_train // batch_size_train):\n",
    "            batch_indices = indices[i * batch_size_train: (i + 1) * batch_size_train]\n",
    "            batch_features = [X_train[i] for i in batch_indices]\n",
    "            batch_stances = [y_train[i] for i in batch_indices]\n",
    "\n",
    "            batch_feed_dict = {features_pl: batch_features, stances_pl: batch_stances, keep_prob_pl: train_keep_prob}\n",
    "            _, current_loss = sess.run([opt_op, loss], feed_dict=batch_feed_dict)\n",
    "            total_loss += current_loss\n",
    "\n",
    "\n",
    "    # Predict\n",
    "    valid_feed_dict = {features_pl: X_valid, keep_prob_pl: 0.9}\n",
    "    test_valid = sess.run(predict, feed_dict=valid_feed_dict)\n",
    "    test_feed_dict = {features_pl: X_test, keep_prob_pl: 1.0}\n",
    "    test_pred = sess.run(predict, feed_dict=test_feed_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame()\n",
    "df['actual'] = y_valid\n",
    "df['pred'] = test_valid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Checking the accuracy of each label and total accuracy of the model on validation dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1875"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(df['actual'],df['pred'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       agree       0.25      0.23      0.24        13\n",
      "    disagree       0.00      0.00      0.00         7\n",
      "     discuss       0.00      0.00      0.00         3\n",
      "   unrelated       0.23      0.33      0.27         9\n",
      "\n",
      "    accuracy                           0.19        32\n",
      "   macro avg       0.12      0.14      0.13        32\n",
      "weighted avg       0.17      0.19      0.17        32\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\fuzel\\anaconda3\\envs\\tf1\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\fuzel\\anaconda3\\envs\\tf1\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\fuzel\\anaconda3\\envs\\tf1\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "target_names = ['agree','disagree','discuss','unrelated']\n",
    "print(classification_report(df['actual'],df['pred'],target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\fuzel\\anaconda3\\envs\\tf1\\lib\\site-packages\\ipykernel_launcher.py:2: RuntimeWarning: invalid value encountered in true_divide\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.25      , 0.        ,        nan, 0.23076923])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix = confusion_matrix(df['actual'],df['pred'])\n",
    "matrix.diagonal()/matrix.sum(axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading the predicted file to compare results "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_file = pd.DataFrame()\n",
    "pred_file['Stance'] = test_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = pd.read_csv(file_test_instances_labeled)\n",
    "y_actual = pd.DataFrame()\n",
    "try:\n",
    "    y_actual['Stance'] = labels['Stance']\n",
    "except:\n",
    "    y_actual['Stance'] = labels['stance']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3488372093023256"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_actual['Stance'],pred_file['Stance'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[6, 3, 0, 8],\n",
       "       [4, 2, 0, 2],\n",
       "       [4, 0, 0, 2],\n",
       "       [5, 0, 0, 7]], dtype=int64)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_actual['Stance'],pred_file['Stance'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf1",
   "language": "python",
   "name": "tf1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
